{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/briand/Desktop/ds course/ipython/data/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#We assume data is in a parallel directory to this one called 'data'\n",
    "cwd = os.getcwd()\n",
    "datadir = '/'.join(cwd.split('/')[0:-1]) + '/data/'\n",
    "print(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Student put in read data command here:\n",
    "data = pd.read_csv(datadir + 'survey_responses_2016.csv', header = 0, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the column headers and use something more descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'cs_python', 'cs_java', 'cs_c', 'cs_perl', 'cs_javascript',\n",
       "       'cs_r', 'cs_sas', 'profile_1', 'profile_2', 'profile_3', 'profile_4',\n",
       "       'profile_5', 'profile_6', 'profile_7', 'fruit', 'len_answer', 'season',\n",
       "       'experience_coded', 'experience'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Student put in code to look at column names\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names like 'profile_1-profile_7' aren't very descriptive. As a quick data maintenance task, let's rename the columns starting with 'profile'. The dictionary in the next cell maps the integer index to a descriptive text.\n",
    "\n",
    "Tactically, let's loop through each column name. Within the loop let's check whether the column name starts with 'profile.' If it does, let's create a new name that swaps the key with the value using profile_mapping dictionary (i.e., profile_1 -> profile_Viz). We then add the new column name to a list. If it doesn't start with 'profile' just add the old column name to the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile_mapping = {1:'Viz',\n",
    "                   2:'CS',\n",
    "                   3:'Math',\n",
    "                   4:'Stats',\n",
    "                   5:'ML',\n",
    "                   6:'Bus',\n",
    "                   7:'Com'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Student put code here to change the header names\n",
    "newcols = []\n",
    "\n",
    "for colname in data.columns:\n",
    "    \n",
    "    if colname[0:7] == 'profile':\n",
    "        \n",
    "        newcols.append('profile_{}'.format(profile_mapping[int(colname[-1])]))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        newcols.append(colname)\n",
    "    \n",
    "#Now swap the old columns with the values in newcols    \n",
    "data.columns = newcols    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this data to illustrate common data analytic techniques. We have one numeric variable (len_answer) and different categorical variables which may carry some signal of the 'len_answer' variable. \n",
    "\n",
    "'Len_answer' is the character count of the response to the following question: \"Besides the examples given in lecture 1, discuss a case where data science has created value for some company. Please explain the company's goals and how any sort of data analysis could have helped the company achieve said goals.\" As this is a subjective business question, let's hypothesize that students with more professional experience might be more likely to give longer answers. \n",
    "\n",
    "In more technical terms, we'll test whether the variance of len_answer can be explained away by the categorical representation of a student's experience. \n",
    "\n",
    "The first thing we should do is look at the distribution of len_answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 41.,  35.,  18.,   5.,   1.,   1.,   0.,   0.,   0.,   1.]),\n",
       " array([    0. ,   368.3,   736.6,  1104.9,  1473.2,  1841.5,  2209.8,\n",
       "         2578.1,  2946.4,  3314.7,  3683. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107c0a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Student - build and plot a histogram here\n",
    "plt.hist(data.len_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have at least one strong outlier and a thick distribution around 0. Let's also use the Pandas describe() method to get a stronger sense of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     102.000000\n",
       "mean      547.725490\n",
       "std       480.267152\n",
       "min         0.000000\n",
       "25%       262.500000\n",
       "50%       460.500000\n",
       "75%       745.750000\n",
       "max      3683.000000\n",
       "Name: len_answer, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.len_answer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider cleaning up the data. We'll remove the max value as well as those with a length less than 20 (which we think is a generous minimum to communicate a reasonable answer.\n",
    "\n",
    "Create a new data_frame that removes these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Student create a filtered data frame here\n",
    "outlier_filter = (data.len_answer > 20) & (data.len_answer < data.len_answer.max())\n",
    "data_clean = data[outlier_filter]\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned our data, let's run a pairwise t-test on each experience level to see if their difference in len_answer is statistically significant. To run a t-test, we'll need the mean, standard-deviation and count for each group. We can achieve this with a pandas groupby operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">len_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-5 years, I'm getting good at what I do!</th>\n",
       "      <td>732.222222</td>\n",
       "      <td>398.570468</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5+ years, I'm a veteran!</th>\n",
       "      <td>717.333333</td>\n",
       "      <td>269.793748</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt; 2 years, I'm fresh!</th>\n",
       "      <td>489.312500</td>\n",
       "      <td>285.271501</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None, I just finished my undergrad!</th>\n",
       "      <td>507.000000</td>\n",
       "      <td>335.536253</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           len_answer                  \n",
       "                                                 mean         std count\n",
       "experience                                                             \n",
       "2-5 years, I'm getting good at what I do!  732.222222  398.570468    18\n",
       "5+ years, I'm a veteran!                   717.333333  269.793748     6\n",
       "< 2 years, I'm fresh!                      489.312500  285.271501    16\n",
       "None, I just finished my undergrad!        507.000000  335.536253    53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Student input code here\n",
    "data_clean_grouped = data_clean[['len_answer', 'experience']].groupby(['experience']).agg(['mean', 'std', 'count'])\n",
    "data_clean_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we can see a potential split between the [0, 2] year experience range and the [2+] experience range. Let's be more rigorous and run t-tests. Let's write a function that takes in the necessary statistics and returns a p-value.\n",
    "\n",
    "Remember, the t-stat for the difference between two means is:\n",
    "\n",
    "<center>$t = \\frac{\\hat{\\mu_1} - \\hat{\\mu_2}}{\\sqrt{\\frac{\\hat{\\sigma_1}^2}{n_1} + \\frac{\\hat{\\sigma_2}^2}{n_2}}}$</center>\n",
    "\n",
    "The p-value can be found using a t-distribution, but for simplicity, let's approximate this with the normal distribution. For the 2-tailed test, the p-value is: 2 * (1 - Norm.CDF(T))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Student complete the function\n",
    "from scipy.stats import norm\n",
    "def pvalue_diffmeans_twotail(mu1, sig1, n1, mu2, sig2, n2):\n",
    "    '''\n",
    "    P-value calculator for the hypothesis test of mu1 != mu2.\n",
    "    Takes in the approprate inputs to compute the t-statistic for the difference between means\n",
    "    Outputs a p-value for a two-sample t-test.\n",
    "    '''\n",
    "    diff = mu1 - mu2\n",
    "    stderror = np.sqrt(sig1**2 / n1 + sig2**2 / n2)\n",
    "    t = diff / stderror\n",
    "    \n",
    "    p_value = 2 * (1- norm.cdf(t))\n",
    "    \n",
    "    return (t, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop through all possible pairs in data_clean_grouped and perform a t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tailed T-Test between groups: 2-5 years, I'm getting good at what I do! and 5+ years, I'm a veteran!\n",
      "Diff = 15.0 characters\n",
      "The t-stat is 0.103 and p-value is 0.918\n",
      "\n",
      "Two tailed T-Test between groups: 2-5 years, I'm getting good at what I do! and < 2 years, I'm fresh!\n",
      "Diff = 243.0 characters\n",
      "The t-stat is 2.059 and p-value is 0.039\n",
      "\n",
      "Two tailed T-Test between groups: 2-5 years, I'm getting good at what I do! and None, I just finished my undergrad!\n",
      "Diff = 225.0 characters\n",
      "The t-stat is 2.152 and p-value is 0.031\n",
      "\n",
      "Two tailed T-Test between groups: 5+ years, I'm a veteran! and < 2 years, I'm fresh!\n",
      "Diff = 228.0 characters\n",
      "The t-stat is 1.738 and p-value is 0.082\n",
      "\n",
      "Two tailed T-Test between groups: 5+ years, I'm a veteran! and None, I just finished my undergrad!\n",
      "Diff = 210.0 characters\n",
      "The t-stat is 1.762 and p-value is 0.078\n",
      "\n",
      "Two tailed T-Test between groups: < 2 years, I'm fresh! and None, I just finished my undergrad!\n",
      "Diff = -18.0 characters\n",
      "The t-stat is -0.208 and p-value is 1.165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Student put in code here:\n",
    "\n",
    "#get distinct values in the data frame for the experience variable\n",
    "\n",
    "#data_grouped = data[['len_answer', 'experience']].groupby(['experience']).agg(['mean', 'std', 'count'])\n",
    "#ttest_data = data_grouped\n",
    "\n",
    "\n",
    "ttest_data = data_clean_grouped\n",
    "\n",
    "\n",
    "grps = ttest_data.index.values\n",
    "\n",
    "#Now loop through each pair\n",
    "for i, grp1 in enumerate(grps):\n",
    "    for grp2 in grps[i + 1:]:\n",
    "    \n",
    "        '''\n",
    "        hint: since the grp name is the index, pull out the record corresponding to that index value. \n",
    "        Also, the result of groupby uses a multi-index. So be sure to index on 'len_answer' as well.\n",
    "        Then pull out the mean, std, and cnt from that result.   \n",
    "        '''        \n",
    "        row1 = ttest_data.ix[grp1].ix['len_answer']\n",
    "        row2 = ttest_data.ix[grp2].ix['len_answer']\n",
    "    \n",
    "        tstat, p_value = pvalue_diffmeans_twotail(row1['mean'], row1['std'], row1['count'], row2['mean'], row2['std'], row2['count'])\n",
    "    \n",
    "        print('Two tailed T-Test between groups: {} and {}'.format(grp1, grp2))\n",
    "        print('Diff = {} characters'.format(round(row1['mean'] - row2['mean'], 0)))\n",
    "        print('The t-stat is {} and p-value is {}'.format(round(tstat, 3), round(p_value, 3)))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some observations you might have about the above results? Are there any with large deviances that are not statistically significant at at least a 95% level?\n",
    "\n",
    "Also, how do the numbers change if you rerun it using the original data, and not the cleaned data. What is the effect of outliers on the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two tailed T-Test between groups: 2-5 years, I'm getting good at what I do! and 5+ years, I'm a veteran!\n",
      "Diff = 79.0 characters\n",
      "The t-stat is 0.466 and p-value is 0.641\n",
      "\n",
      "Two tailed T-Test between groups: 2-5 years, I'm getting good at what I do! and < 2 years, I'm fresh!\n",
      "Diff = 54.0 characters\n",
      "The t-stat is 0.252 and p-value is 0.801\n",
      "\n",
      "Two tailed T-Test between groups: 2-5 years, I'm getting good at what I do! and None, I just finished my undergrad!\n",
      "Diff = 230.0 characters\n",
      "The t-stat is 2.148 and p-value is 0.032\n",
      "\n",
      "Two tailed T-Test between groups: 5+ years, I'm a veteran! and < 2 years, I'm fresh!\n",
      "Diff = -25.0 characters\n",
      "The t-stat is -0.104 and p-value is 1.083\n",
      "\n",
      "Two tailed T-Test between groups: 5+ years, I'm a veteran! and None, I just finished my undergrad!\n",
      "Diff = 152.0 characters\n",
      "The t-stat is 1.04 and p-value is 0.298\n",
      "\n",
      "Two tailed T-Test between groups: < 2 years, I'm fresh! and None, I just finished my undergrad!\n",
      "Diff = 176.0 characters\n",
      "The t-stat is 0.894 and p-value is 0.372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rerun everything without cleaning outliers\n",
    "data_grouped = data[['len_answer', 'experience']].groupby(['experience']).agg(['mean', 'std', 'count'])\n",
    "ttest_data = data_grouped\n",
    "\n",
    "\n",
    "grps = ttest_data.index.values\n",
    "\n",
    "#Now loop through each pair\n",
    "for i, grp1 in enumerate(grps):\n",
    "    for grp2 in grps[i + 1:]:\n",
    "    \n",
    "        '''\n",
    "        hint: since the grp name is the index, pull out the record corresponding to that index value. \n",
    "        Also, the result of groupby uses a multi-index. So be sure to index on 'len_answer' as well.\n",
    "        Then pull out the mean, std, and cnt from that result.   \n",
    "        '''        \n",
    "        row1 = ttest_data.ix[grp1].ix['len_answer']\n",
    "        row2 = ttest_data.ix[grp2].ix['len_answer']\n",
    "    \n",
    "        tstat, p_value = pvalue_diffmeans_twotail(row1['mean'], row1['std'], row1['count'], row2['mean'], row2['std'], row2['count'])\n",
    "    \n",
    "        print('Two tailed T-Test between groups: {} and {}'.format(grp1, grp2))\n",
    "        print('Diff = {} characters'.format(round(row1['mean'] - row2['mean'], 0)))\n",
    "        print('The t-stat is {} and p-value is {}'.format(round(tstat, 3), round(p_value, 3)))\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
